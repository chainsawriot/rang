---
title: 'rang: Reconstructing reproducible R computational environments'
tags:
  - R
  - reproducibility
  - docker
authors:
  - name: "Chung-hong Chan"
    orcid: 0000-0002-6232-7530
    affiliation: GESIS Leibniz-Institut für Sozialwissenschaften
  - name: "David Schoch"
    orcid: 0000-0003-2952-4812
    affiliation: GESIS Leibniz-Institut für Sozialwissenschaften    
abstract: |
  A complete declarative description of the computational environment is often missing when researchers share their materials. Without such description, software obsolescence and missing system components can jeopardize computational reproducibility in the future, even when data and computer code are available. The R package rang is a complete solution for generating the declarative description for other researchers to automatically reconstruct the computational environment at a specific time point. The reconstruction process, based on Docker, has been tested for R code as old as 2005 and does not depend on the long term availability of any commercial service. The description generated by rang satisfies the definition of a reproducible research compendium and can be shared as such. In this contribution, we show how rang can be used to make otherwise unexecutable code, spanning from fields such as computational social science and bioinformatics, executable again. We also provide instructions on how to use rang to construct reproducible and shareable research compendium of current research. The package is currently available from CRAN (https://cran.r-project.org/web/packages/rang/index.html) and GitHub (https://github.com/chainsawriot/rang).
keywords:
  - R
  - reproducibility
  - docker
year: 2023
bibliography: paper.bib
format:
  pdf: default
  arxiv-pdf:
    keep-tex: true
---

# Introduction

The ability to reconstruct the computational environment is one of the most important aspects of reproducibility. In the realm of R, the important aspects are what and which version of installed R packages as well as the exact R version.

## Existing solutions

`renv` [@renvrpkg] (and its derivatives such as `jetpack` and its predecessor `packrat`) takes a similar approach to Python's `virtualenv` and Ruby's `Gem` to pin down the exact version of R packages using a "lock file". `containerit` [@nuest:2019] takes the current state of the computational environment and "containerize" it as a Dockerfile. But `containerit` does not pin down the exact version of R packages. Other solutions such as `groundhog` [@groundhogrpkg] and `checkpoint` [@checkpointrpkg] depend on the availability of The Microsoft R Application Network (MRAN), which will be shut down on July 1st, 2023. 

These solutions are better for prospective usage, i.e. using them now to ensure the reproducibility of the current research for future researchers. `rang` mostly targets retrospective usage, i.e. using `rang` to reconstruct historical R computational environments which have not been completely declared. One can think of `rang` as an archaeological tool. In Section 3, `rang` is used to enable the reproducibility of published literature.

# Basic usage

There are two important functions of `rang`: `resolve()` and `dockerize()`.

`resolve()` queries various web services from the r-hub project of the R Consortium for information about R packages at a specific time point that is necessary for reconstructing a computational environment, e.g. (deep) dependencies, system requirements, and R version. For instance, if there was a computational environment constructed on 2020-01-16 (called "snapshot date") with the several natural language processing R packages, `resolve()` can be used to resolve all the dependencies of these R packages. Currently, `rang` supports CRAN, Bioconductor, and GitHub packages.

```r
library(rang)
graph <- resolve(pkgs = c("openNLP", "LDAvis", "topicmodels", "quanteda"),
                 snapshot_date = "2020-01-16")
graph
```

The resolved result is an S3 object called `rang`. The information contained in a `rang` object can then be used to construct a computational environment in a similar manner as `containerit`, but with the packages and R versions pinned on the snapshot date. Then, the function `dockerize()` is used to generate the `Dockerfile` and other scripts in the `output_dir`. 

```r
dockerize(graph, output_dir = "docker")
```

For R >= 3.1, the images from the Rocker project are used [@boettiger:2017:IR]. For R < 3.1 but >= 2.1, a custom image based on Debian Woody is used. As of writing, `rang` does not support R < 2.1, i.e. snapshot date earlier than 2005-04-19. The development to support R < 2.1 is in progress. There are two features of `dockerize()` that are important for future reproducibility. 

1. By default, the container building process downloads source packages from CRAN and then compiles them from source. This step depends on the future availability of R packages on CRAN (which is extremely likely to be the case in the near future, given the continuous availability since 1997-04-23) [^1]. However, it is also possible to cache (or archive) the source packages now. The archived R packages can then be used instead during the building process.

[^1]: https://stat.ethz.ch/pipermail/r-announce/1997/000001.html

```r
dockerize(graph, output_dir = "docker", cache = TRUE)
```

2. It is also possible to install R packages in a separate library during the building process to isolate all these R packages from the main library.

```r
dockerize(graph, output_dir = "docker", cache = TRUE,
          lib = "anotherlibrary")
```

For the sake of completeness, the instructions for building and running the Docker container on Unix-like systems are included here.

```bash
cd docker
## might need to sudo
docker build -t rang .
docker run --rm --name "rangtest" -ti rang
```

# Case Studies

The following are some examples of how `rang` can be used to make otherwise shared, but unexecutable, R code runnable again. The examples were drawn from various fields spanning from political science, psychological science, and bioinformatics.

## quanteda JOSS paper

The software paper of the text analysis R package `quanteda` was published on 2018-10-06 [@benoit:2018]. In the paper, the following R code snippet is included.

```r
library("quanteda")
# construct the feature co-occurrence matrix
examplefcm <-
tokens(data_corpus_irishbudget2010, remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"), padding = FALSE) %>%
fcm(context = "window", window = 5, tri = FALSE)
# choose 30 most frequency features
topfeats <- names(topfeatures(examplefcm, 30))
# select the top 30 features only, plot the network
set.seed(100)
textplot_network(fcm_select(examplefcm, topfeats), min_freq = 0.8)
```

On 2023-02-08, this code snippet is not executable with the current version of `quanteda` (3.2.4). It is possible to install the "period appropriate" version of `quanteda` (1.3.4) using `remotes` on the current version of R (4.2.2). And indeed, the above code snippet can still be executed.

```r
remotes::install_version("quanteda", version = "1.3.4")
```

The issue is that installing `quanteda` 1.3.4 this way installs the latest dependencies from CRAN. `quanteda` 1.3.4 uses a deprecated (but not yet removed) function of `Matrix` (`as(<dgTMatrix>, "dgCMatrix")`). If this function were removed in the future, the above code snippet would not be executable anymore.

Using `rang`, one can query the version of `quanteda` on 2018-10-06 and create a Docker container with all the "period appropriate" dependencies. Here, the `rstudio` Rocker image is selected.

```r
library(rang)
graph <- resolve(pkgs = "quanteda",
                 snapshot_date = "2018-10-06",
                 os = "ubuntu-18.04")
dockerize(graph, output_dir = "quanteda_docker",
          image = "rstudio")
```

The above code snippet can be executed with the generated container without any problem (@fig-figure1).

```{r}
#| fig.cap: The code snippet running in a R 3.5.1 container created with rang
#| echo: FALSE
#| label: fig-figure1
knitr::include_graphics("quanteda_rstudio.png", dpi = 300)
```

## Psychological Science

 @cruewell:2023:WB evaluate the computational reproducibility of 14 articles published in *Psyhocological Science*. Among these articles, the paper by @hilgard:2019:NEG has been rated as having "package dependency issues".

All data and computer code are available from GitHub with the last commit on 2019-01-17 [^hilgard]. The R code contains a list of R packages used in the project as `library()` statements, including an R package on GitHub that is written by the main author of that paper. However, we identified one package (`compute.es`) that was not written in those `library()` statements but used with the namespace operator, i.e. `compute.es::tes()`. This undocumented package can be detected by `renv::dependencies()`.

[^hilgard]: https://github.com/Joe-Hilgard/vvg-2d4d

Based on the above information, one can run `resolve()` to obtain the dependency graph of all R packages on 2019-01-17.

```r
graph <- resolve(c("readxl", "rms", "ordinal", "tidyverse", "lubridate", "MBESS",
                   "censReg", "BayesFactor", "psych", "Joe-Hilgard/hilgard", "lsmeans",
                   "compute.es"),
                 snapshot_date = "2019-01-17")
```

When running `dockerize()`, one can take advantage of the `materials_dir` parameter to transfer the shared materials from @hilgard:2019:NEG into the Docker image.

```r
dockerize(graph, "hilgard", materials_dir = "vvg-2d4d", cache = TRUE)
```

We then built the Docker and launch a Docker container. For this container, we changed the entry point from R to bash so that the container goes to the Linux command shell instead.

```r
cd hilgard
docker build -t hilgard .
docker run --rm --name "hilgardcontainer" --entrypoint bash -ti hilgard
```

Inside the container, the materials are located in the `materials` directory. We used the following shell script to test the reproducibility of all R scripts.

```sh
cd materials
rfiles=(0_data_aggregation.R 1_data_cleaning.R 2_analysis.R 3_plotting.R)
for i in ${rfiles[@]}
do
	Rscript $i
	code=$?
	if [ $code != 0 ]
	then
		exit 1
	fi
done   
```

All R scripts ran fine inside the container and the figures generated are the same as the ones in @hilgard:2019:NEG.

## Political Analysis

The study by @trisovic:2022 evaluates the reproducibility of R scripts shared on Dataverse. They found that 75\% of R scripts cannot be successfully executed. Among these failed R scripts is an R script shared by @beck:2019:EGD.

This R script has been "rescued" by the author of the R package `groundhog` [@groundhogrpkg], as demonstrated in a blog post [^groundhog]. We were wondering if `rang` can also be used to "rescue" the concerned R script. The date of the R script, as indicated on Dataverse, is 2018-12-12. This date is used as the snapshot date.

```r
graph <- resolve(c("foreign", "bife"), snapshot_date = "2018-12-12")
dockerize(graph, output_dir = "nat", materials_dir = "nathaniel")
```

```r
cd nat
docker build -t nat .
docker run --rm --name "natcontainer" --entrypoint bash -ti nat
```

Inside the container

```r
cd materials
Rscript fn_5.R
```

The same file can also be "rescued" by `rang`.

[^groundhog]: http://datacolada.org/100

## Recover a removed R package: maxent

The R package `maxent` introduces a machine learning algorithm with a small memory footprint and was available on CRAN until 2019. A software paper was published by the original authors in 2012 [@jurka:2012]. The R package was also used in some subsequent automated content analytic papers [e.g. @loercher:2017:D]. Despite the covert editing of the package by a staffer of CRAN [^evidence], the package was removed from CRAN in 2019 [^checkerror]. We attempted to install the second last (the original submitted version) and last (with covert editing) versions of `maxent` on R 4.2.2. Both of them didn't work.

Using `rang`, we are able to reconstruct a computational environment with R 2.15.0 (2012-03-30) to run all code snippets published in @jurka:2012 [^speed]. For removed CRAN packages, we strongly recommend querying the Github read-only mirror of CRAN instead (https://github.com/cran). It is because in this way, the resolved system requirements have a higher chance of being correct.

```r
maxent <- resolve("cran/maxent", "2012-06-10")
dockerize(maxent, "maxentdir", cache = TRUE)
```

[^checkerror]: https://cran-archive.r-project.org/web/checks/2019/2019-03-05_check_results_maxent.html

[^evidence]: https://github.com/cran/maxent/commit/9d46c6aad27a1f41a78907b170ddd9a586192be9

[^speed]: On an interesting historical side note: The original paper reported ---based on a benchmark--- that "the algorithm is very fast; `maxent` uses only 135.4 megabytes of RAM and finishes in 53.3 seconds." On a modest computer in 2023 with a dockerized R 2.15.0, the benchmark finishes in 4 seconds.

## Recover a removed R package: ptproc

The software paper of the R package `ptproc` was published in 2003 and introduced multidimensional point process models [@peng:2003:MDP]. But the package has been removed from CRAN for over a decade (at least). The only release on CRAN was on 2002-10-10. The package is still listed in the "Handling and Analyzing Spatio-Temporal Data" CRAN Task View [^taskview] despite being uninstallable without modification on any modern R system (see below). As of writing, the package, as a tarball file (tar.gz), is still downloadable from the original author's website [^peng].

[^taskview]: https://cran.r-project.org/web/views/SpatioTemporal.html

Even with this over-a-decade removal and new packages with similar functionalities have been created, there is evidence that `ptproc` is still being sought for. As late as 2017, there are blog posts on how to install the long obsolete package on modern R [^blog]. The package is extremely challenging to install on a modern R system because the package was written before the introduction of name space management in R 1.7.0 [@RN-2003-001]. In other words, the available tarball file from the original author's website does not contain a `NAMESPACE` file as all other modern R packages do.

The oldest version of R that `rang` can support, as of writing, is R 1.3.1. `rang` is probably the only solution available that can support the 1.x series of R (i.e. before 2004-10-04). Similar to the case of `maxent` above, a Dockerfile to generate a Docker image with `ptproc` installed can be generated with two lines of code.

```r
graph <- resolve("ptproc", snapshot_date = "2004-07-01")
dockerize(graph, "~/dev/misc/ptproc", cache = TRUE)
```

Suppose we have an R script, extracted from @peng:2003:MDP, called "peng.R" like this:

```r
require(ptproc)

set.seed(1000)
x <- cbind(runif(100), runif(100), runif(100))
hPois.cond.int <- function(params, eval.pts, pts = NULL, data = NULL, TT = NULL) {
    mu <- params[1]
    if(is.null(TT))
        rep(mu, nrow(eval.pts))
    else {
        vol <- prod(apply(TT, 2, diff))
        mu * vol
    }
}
ppm <- ptproc(pts = x, cond.int = hPois.cond.int, params = 50,
              ranges = cbind(c(0,1), c(0,1), c(0,1)))
fit <- ptproc.fit(ppm, optim.control = list(trace = 2), method = "BFGS")
summary(fit)
```

One can integrate `rang` into a BASH script to completely automate the batch execution of the above R script.

```bash
Rscript -e "require(rang); dockerize(resolve('ptproc', '2004-07-01'),
'pengdocker', cache = TRUE)"
docker build -t pengimg ./pengdocker
## launching a container in daemon mode -d
docker run -d --rm --name "pengcontainer" -ti pengimg
docker cp peng.R pengcontainer:/peng.R
docker exec pengcontainer R CMD BATCH peng.R
docker exec pengcontainer cat peng.Rout
docker cp pengcontainer:/peng.Rout peng.Rout
docker stop pengcontainer
```

The file `peng.Rout` contains the execution results of the script from inside the Docker container. As the random seed was preserved by the original author [@peng:2003:MDP], the above BASH script can perfectly reproduce the analysis [^random].

[^peng]: https://www.biostat.jhsph.edu/~rpeng/software/

[^blog]: https://blog.mathandpencil.com/installing-ptproc-on-osx and https://tomaxent.com/2017/03/16/Installing-ptproc-on-Ubuntu-16-04-LTS/

[^random]: It is also important to note that the random number generator (RNG) of R has been changed several times over the course of the development. In this case, we are using the same generation of RNG as @peng:2003:MDP.

## Recover a removed Bioconductor package

Similar to CRAN, Bioconductor is a series of repositories of R package for bioinformatics and computational biology. Also similar to CRAN, packages can get removed over time.

The Bioconductor package `Sushi` has been deprecated by the original authors and is removed from Bioconductor version 3.16 (2022-11-02). `Sushi` is a data visualization tool for genomic data and was used in many online tutorials and scientific papers, including the original paper announcing the package by the original authors [@phanstiel:2014:S].

`rang` has native support for Bioconductor packages since 0.2. We obtained the R script `"PaperFigure.R"` from the Github repo of `Sushi` [^sushi], which generates the figure in @phanstiel:2014:S. Similar to the above case of `ptproc`, we made a completely automated BASH script to run `"PaperFigure.R"` and get the generated figure out of the container (@fig-figure2). We made no modification to `"PaperFigure.R"`.

```sh
Rscript -e "require(rang); dockerize(resolve('Sushi', '2014-06-05'),
'sushidocker', no_rocker = TRUE, cache = TRUE)"
docker build -t sushiimg ./sushidocker
docker run -d --rm --name "sushicontainer" -ti sushiimg
docker cp PaperFigure.R sushicontainer:/PaperFigure.R
docker exec sushicontainer mkdir vignettes
docker exec sushicontainer R CMD BATCH PaperFigure.R
docker cp sushicontainer:/vignettes/Figure_1.pdf sushi_figure1.pdf
docker stop sushicontainer
```

```{r}
#| fig.cap: The figure from the batch execution of `PaperFigure.R` inside a Docker container generated by `rang`
#| echo: FALSE
#| label: fig-figure2
knitr::include_graphics("sushi_figure1.pdf", dpi = 300)
```

[^sushi]: https://github.com/PhanstielLab/Sushi/blob/master/vignettes/PaperFigure.R

# Preparing research compendia with long-term computational reproducibility

The above six examples show how useful it is for `rang` reconstructing tricky computational environments which have not been completely declared in the literature. Although we position `rang` mostly as an archaeological tool, we also think that `rang` can also be used to prepare research compendia of current research. We can't predict the future but research compendia generated by `rang` would probably have long-term computational reproducibility.

To demonstrate this point, we took the recent paper by @oser:2022:HPE. This paper was selected because 1) the paper was published in *Political Communication*, a high impact journal that awards Open Science Badges; 2) shared data and R code are available; and most importantly, 3) the shared R code is well-written. In the repository of this paper, we based on the materials shared by @oser:2022:HPE and prepared a research compendium that should have long-term computational reproducibility. The research compendium is similar to the Executable Compendium suggested by the Turing way.

The preparation of the research compendium is easy as `rang` can scan a materials directory for all R packages used [^dmetar].

```r
require(rang)
## meta-analysis is the directory of all shared materials
cran_pkgs <- as_pkgrefs("meta-analysis") 

## dmetar is an undeclared github package: MathiasHarrer/dmetar
cran_pkgs[cran_pkgs == "cran::dmetar"] <- "MathiasHarrer/dmetar"
x <- resolve(cran_pkgs, "2021-08-11", verbose = TRUE)
print(x, all_pkgs = TRUE)
dockerize(x, "oser_docker", materials_dir = "meta-analysis", cache = TRUE)
```

The above R script is saved as `oser.R`. The central piece of the executable compendium is the `Makefile`.

```Makefile
rmd = "rmarkdown::render('materials/README.Rmd', output_file = 'reproduced.html')"
resolve:
	Rscript oser.R
build: oser_docker
	docker build -t oserimg oser_docker
render:
	docker run -d --rm --name "osercontainer" -ti oserimg
	docker exec osercontainer Rscript -e ${rmd}
	docker cp osercontainer:/materials/reproduced.html oser_README.html
	docker stop osercontainer
export:
	docker save oserimg | gzip > oserimg.tar.gz
rebuild: oserimg.tar.gz
	docker load < oserimg.tar.gz
all: resolve build render
	echo "finished"
```

With this `Makefile`, once can create the Dockerfile with `make resolve`, build the Docker image with `make build`, render the RMarkdown file inside the container with `make render`, export the built Docker image with `make export`, and rebuild the exported Docker image with `make rebuild`.

The structure of the executable compendium looks like this:

```bash
Makefile
oser.R
meta-analysis/
README.md
oser_docker/
oserimg.tar.gz
```

In this executable compendium, only the first four elements are essential. The directory `oser_docker` (116 MB) contains cached R packages, Dockerfile, and a further copy of the directory `meta-analysis/` to be transferred into the Docker image. That can be regenerated by running `make resolve`. However, having this directory preserved insures against the situations of some R packages used in the project are no longer available or any of the information providers used by `rang` for resolving the dependency relationships being not available. (Or in the rare circumstance of `rang` is no longer available.)

`oserimg.tar.gz` (667 MB) is a backup copy of the Docker image. This can be regenerated by running `make export`. Preserving this file insurces against all the situations mentioned above, but also the situations of Docker Hub and the software repositories used by the dockerized operating system being not available. As a matter of fact, when `oserimg.tar.gz` is available it is possible to run `make rebuild` and `make render` even without internet access, provided that only Docker and make have been preinstalled. Of course, there is still an extremely rare situation where Docker (the program) itself is no longer available. However, it is possible to convert the image file for use on other containerization solutions such as Singularity [^singularity].

Sharing of research artefacts less than 1G is not as challenging as it used to be. Zenodo, for example, allows the sharing of 50G of files. Therefore, sharing of the last two components of the executable compendium prepared with `rang` is at least possible on Zenodo. However, for data repositories with more restrictions on data size, sharing the executable compendium without the last two parts could be considered sufficient. For that, run `make all` will generate all the things needed for reproducing the analysis inside a container.

[^singularity]: https://docs.sylabs.io/guides/3.0/user-guide/singularity_and_docker.html

[^dmetar]: We detected a minor issue in the code base that an undeclared Github package is used. But it can be easily solved, as in the Psychological Science example above.

# Conclusion

# References
